{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b928344f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0648688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5afd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32b0a2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d48c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Data ===\n",
    "# def load_data(file_path):\n",
    "#     return pd.read_csv(file_path, sep=';', names=['text', 'label'])\n",
    "\n",
    "# train = load_data('data/train.txt')\n",
    "# val = load_data('data/val.txt')\n",
    "# test = load_data('data/test.txt')\n",
    "\n",
    "# trainval = pd.concat([train, val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d33a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the single CSV file\n",
    "train = pd.read_csv('data/train.csv',names=['text', 'label'])\n",
    "test = pd.read_csv('data/test.csv',names=['text', 'label'])\n",
    "\n",
    "# === Label Encoding ===\n",
    "label_encoder = LabelEncoder()\n",
    "train['label_enc'] = label_encoder.fit_transform(train['label'])\n",
    "test['label_enc'] = label_encoder.transform(test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63486a",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7692dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define Models ===\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    # \"Random Forest\": RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a21cb",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ee1f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Training: Logistic Regression\n",
      "âœ… Logistic Regression - Accuracy: 0.8955, F1: 0.8948\n",
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.89      0.90      0.90     11463\n",
      "        fear       0.84      0.84      0.84      9542\n",
      "         joy       0.91      0.93      0.92     28214\n",
      "        love       0.80      0.75      0.78      6911\n",
      "     sadness       0.94      0.94      0.94     24238\n",
      "    surprise       0.77      0.69      0.73      2994\n",
      "\n",
      "    accuracy                           0.90     83362\n",
      "   macro avg       0.86      0.84      0.85     83362\n",
      "weighted avg       0.89      0.90      0.89     83362\n",
      "\n",
      "ðŸ§© Confusion Matrix:\n",
      "[[10299   357   209    39   548    11]\n",
      " [  390  8022   201    33   484   412]\n",
      " [  153   151 26299  1134   337   140]\n",
      " [   44    24  1545  5196    89    13]\n",
      " [  610   413   327    70 22763    55]\n",
      " [   17   577   236    14    76  2074]]\n",
      "\n",
      "ðŸ”„ Training: XGBoost\n",
      "âœ… XGBoost - Accuracy: 0.8960, F1: 0.8975\n",
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.90      0.90      0.90     11463\n",
      "        fear       0.87      0.83      0.85      9542\n",
      "         joy       0.93      0.90      0.91     28214\n",
      "        love       0.75      0.91      0.82      6911\n",
      "     sadness       0.96      0.91      0.93     24238\n",
      "    surprise       0.68      0.91      0.78      2994\n",
      "\n",
      "    accuracy                           0.90     83362\n",
      "   macro avg       0.85      0.89      0.87     83362\n",
      "weighted avg       0.90      0.90      0.90     83362\n",
      "\n",
      "ðŸ§© Confusion Matrix:\n",
      "[[10274   282   418    47   415    27]\n",
      " [  330  7911   284    40   222   755]\n",
      " [  159   215 25388  1832   318   302]\n",
      " [   35    28   495  6280    53    20]\n",
      " [  559   539   711   153 22129   147]\n",
      " [    8   165    86     9    16  2710]]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\nðŸ”„ Training: {name}\")\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(train['text'], train['label_enc'])\n",
    "    y_pred = pipeline.predict(test['text'])\n",
    "    y_true = test['label_enc']\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"âœ… {name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "    print(\"ðŸ“Š Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(\"ðŸ§© Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # âœ… Save model and confusion matrix\n",
    "    model_dir = f'model/{name}'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(model_dir, f'{name}_model.pkl')\n",
    "    joblib.dump(pipeline, model_path)\n",
    "\n",
    "    # Save confusion matrix\n",
    "    cm_df = pd.DataFrame(conf_matrix, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "    cm_df.to_csv(os.path.join(model_dir, 'confusion_matrix.csv'))\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"path\": model_path\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c99983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/label_encoder.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_encoder, 'model/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc834d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('model/model_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
